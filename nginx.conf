# =============================================================================
# MMCD Dashboard - nginx Reverse Proxy / Load Balancer
# =============================================================================
# Shiny Server Open Source runs ONE R process per app (R is single-threaded).
# To achieve true concurrent user loading, we run multiple Shiny Server
# instances on different internal ports and let nginx distribute users
# across them. Each instance has its own independent R process per app.
#
# Architecture:
#   Client :3838 → nginx → instance-1 :3839
#                        → instance-2 :3840
#                        → instance-3 :3841
#
# The SHINY_WORKERS env var controls the number of instances (default: 3).
# =============================================================================

worker_processes auto;
pid /run/nginx.pid;
error_log /var/log/nginx/error.log warn;

events {
    worker_connections 1024;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format main '$remote_addr - $remote_user [$time_local] '
                    '"$request" $status $body_bytes_sent '
                    '"$http_referer" "$http_user_agent" '
                    'upstream=$upstream_addr';

    access_log /var/log/nginx/access.log main;

    sendfile    on;
    tcp_nopush  on;
    tcp_nodelay on;

    # Keep-alive for client connections
    keepalive_timeout 65;

    # -------------------------------------------------------------------------
    # Upstream: multiple Shiny Server instances
    # -------------------------------------------------------------------------
    # least_conn distributes requests to the instance with fewest active
    # connections, enabling true load balancing even from same IP.
    # This allows concurrent testing from localhost and handles corporate
    # VPN/proxy scenarios in production.
    # -------------------------------------------------------------------------
    # -------------------------------------------------------------------------
    # WebSocket support map (required for Shiny)
    # -------------------------------------------------------------------------
    map $http_upgrade $connection_upgrade {
        default upgrade;
        ''      close;
    }
    
    # -------------------------------------------------------------------------
    # Connection reuse for better performance and health checks
    # -------------------------------------------------------------------------
    upstream shiny_workers {
        least_conn;
        keepalive 32;

        # These must match the ports generated by startup.sh
        # Default: 3 instances on ports 3839, 3840, 3841
        server 127.0.0.1:3839 max_fails=3 fail_timeout=30s;
        server 127.0.0.1:3840 max_fails=3 fail_timeout=30s;
        server 127.0.0.1:3841 max_fails=3 fail_timeout=30s;
    }

    # -------------------------------------------------------------------------
    # Main server block - proxy all requests to Shiny instances
    # -------------------------------------------------------------------------
    server {
        listen 3838;
        server_name _;

        # Max upload size (for any file-upload Shiny inputs)
        client_max_body_size 50m;
        
        # Connection timeouts optimized for Shiny
        client_body_timeout 60s;
        client_header_timeout 60s;

        # ----- Proxy everything to Shiny Server instances -----
        location / {
            proxy_pass http://shiny_workers;

            # HTTP/1.1 + WebSocket upgrade (critical for Shiny)
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection $connection_upgrade;

            # Forward real client info
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # Long timeouts for Shiny's long-lived WebSocket connections
            proxy_connect_timeout 60s;
            proxy_read_timeout 86400s;
            proxy_send_timeout 86400s;

            # Don't buffer – stream responses immediately
            proxy_buffering off;
            proxy_request_buffering off;
            
            # Connection reuse
            proxy_set_header Connection "";
        }
    }
}
